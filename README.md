# RLHF-Dialogue-Summarizer-with-PPO-and-Reward-Model
This project implements RLHF to fine-tune a FLAN-T5 language model for dialogue summarization. The training pipeline involves previous PEFT model, dataset preparation, reward modeling that leveraging a toxicity classifier, implementing PPO-based RL with trl library and evaluation before and after RLHF training.
